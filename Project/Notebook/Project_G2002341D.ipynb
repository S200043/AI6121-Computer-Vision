{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI6121 Computer Vision Course Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "if torch.cuda.is_available():\n",
    "  dev = torch.device('cuda')\n",
    "else:\n",
    "  dev = torch.device('cpu')\n",
    "dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root = '', download = True, transform = transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.MNIST(root = '', download = True, train = False, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_dataset.data.shape)\n",
    "display(test_dataset.data.shape)\n",
    "display(train_dataset.targets.shape)\n",
    "display(test_dataset.targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_padding(input_size, kernel_size = 3, stride = 1):\n",
    "  # Based on formula Output_Size = [(Input_Size - Kernel_Size + 2 * Padding)/Stride] + 1\n",
    "  return int(((input_size - 1) * stride + kernel_size - input_size) / 2)\n",
    "\n",
    "class AverageMeter(object):\n",
    "  # Code from https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "  \"\"\"Computes and stores the average and current value\"\"\"\n",
    "  def __init__(self, name, fmt=':f'):\n",
    "    self.name = name\n",
    "    self.fmt = fmt\n",
    "    self.reset()\n",
    "\n",
    "  def reset(self):\n",
    "    self.val = 0\n",
    "    self.avg = 0\n",
    "    self.sum = 0\n",
    "    self.count = 0\n",
    "\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count\n",
    "\n",
    "  def __str__(self):\n",
    "    fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "    return fmtstr.format(**self.__dict__)\n",
    "\n",
    "class ProgressMeter(object):\n",
    "  # Code from https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "  def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "    self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "    self.meters = meters\n",
    "    self.prefix = prefix\n",
    "\n",
    "  def display(self, batch):\n",
    "    entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "    entries += [str(meter) for meter in self.meters]\n",
    "    print('\\t'.join(entries))\n",
    "\n",
    "  def _get_batch_fmtstr(self, num_batches):\n",
    "    num_digits = len(str(num_batches // 1))\n",
    "    fmt = '{:' + str(num_digits) + 'd}'\n",
    "    return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "  # Code from https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "  \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "  with torch.no_grad():\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "      correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "      res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, show_progress = True):\n",
    "  # Code from https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "  batch_time = AverageMeter('Time', ':6.3f')\n",
    "  data_time = AverageMeter('Data', ':6.3f')\n",
    "  losses = AverageMeter('Loss', ':.4e')\n",
    "  top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "  top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "  losses_ = []\n",
    "  top1_ = []\n",
    "  top5_ = []\n",
    "  progress = ProgressMeter(\n",
    "    len(train_loader),\n",
    "    [batch_time, data_time, losses, top1, top5],\n",
    "    prefix=\"Epoch: [{}] Train:\".format(epoch))\n",
    "\n",
    "  # switch to train mode\n",
    "  model.train()\n",
    "\n",
    "  end = time.time()\n",
    "  for i, (images, target) in enumerate(train_loader):\n",
    "    # measure data loading time\n",
    "    data_time.update(time.time() - end)\n",
    "\n",
    "    images = images.to(dev, non_blocking=True)\n",
    "    target = target.to(dev, non_blocking=True)\n",
    "\n",
    "    # compute output\n",
    "    output = model(images)\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    # measure accuracy and record loss\n",
    "    acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "    losses.update(loss.item(), images.size(0))\n",
    "    top1.update(acc1[0], images.size(0))\n",
    "    top5.update(acc5[0], images.size(0))\n",
    "    losses_.append(loss.item())\n",
    "    top1_.append(acc1)\n",
    "    top5_.append(acc5)\n",
    "\n",
    "    # compute gradient and do SGD step\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # measure elapsed time\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "\n",
    "    if show_progress:\n",
    "      progress.display(i)\n",
    "\n",
    "  return losses_, top1_, top5_\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch, show_progress = True):\n",
    "  # Code from https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "  batch_time = AverageMeter('Time', ':6.3f')\n",
    "  losses = AverageMeter('Loss', ':.4e')\n",
    "  top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "  top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "  losses_ = []\n",
    "  top1_ = []\n",
    "  top5_ = []\n",
    "  progress = ProgressMeter(\n",
    "    len(val_loader),\n",
    "    [batch_time, losses, top1, top5],\n",
    "    prefix=\"Epoch: [{}] Test:\".format(epoch))\n",
    "\n",
    "  # switch to evaluate mode\n",
    "  model.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(val_loader):\n",
    "      images = images.to(dev, non_blocking=True)\n",
    "      target = target.to(dev, non_blocking=True)\n",
    "\n",
    "      # compute output\n",
    "      output = model(images)\n",
    "      loss = criterion(output, target)\n",
    "\n",
    "      # measure accuracy and record loss\n",
    "      acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "      losses.update(loss.item(), images.size(0))\n",
    "      top1.update(acc1[0], images.size(0))\n",
    "      top5.update(acc5[0], images.size(0))\n",
    "      losses_.append(loss.item())\n",
    "      top1_.append(acc1)\n",
    "      top5_.append(acc5)\n",
    "\n",
    "      # measure elapsed time\n",
    "      batch_time.update(time.time() - end)\n",
    "      end = time.time()\n",
    "\n",
    "    if show_progress:\n",
    "      progress.display(i)\n",
    "\n",
    "    # TODO: this should also be done with the ProgressMeter\n",
    "    print('Epoch {epoch:d} * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'.format(epoch=epoch, top1=top1, top5=top5))\n",
    "\n",
    "  return losses_, top1_, top5_\n",
    "\n",
    "def train_epochs(net, bs, criterion, optimizer, epochs, start_epoch = 1, shuffle = True, num_workers = 0, scheduler = None, show_progress = True):\n",
    "  train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = bs,\n",
    "    shuffle = shuffle,\n",
    "    num_workers = num_workers,\n",
    "    pin_memory = True)\n",
    "\n",
    "  val_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = bs,\n",
    "    num_workers = num_workers,\n",
    "    pin_memory = True)\n",
    "\n",
    "  train_losses = []\n",
    "  train_top1 = []\n",
    "  train_top5 = []\n",
    "  val_losses = []\n",
    "  val_top1 = []\n",
    "  val_top5 = []\n",
    "\n",
    "  for epoch in range(start_epoch, epochs + 1):\n",
    "    log = []\n",
    "    a, b, c = train(train_loader, net, criterion, optimizer, epoch, show_progress)\n",
    "    train_losses.append(a)\n",
    "    train_top1.append(b)\n",
    "    train_top5.append(c)\n",
    "    a, b,c = validate(val_loader, net, criterion, epoch, show_progress)\n",
    "    val_losses.append(a)\n",
    "    val_top1.append(b)\n",
    "    val_top5.append(c)\n",
    "    if scheduler != None:\n",
    "      scheduler.step()\n",
    "\n",
    "  return train_losses, train_top1, train_top5, val_losses, val_top1, val_top5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "\n",
    "  def __init__(self, in_channels, input_size, hidden_size, output_size, kernel_size = 3, stride = 1):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = hidden_size, kernel_size = kernel_size, stride = 1, padding = calculate_padding(input_size))\n",
    "    self.conv2 = nn.Conv2d(in_channels = hidden_size, out_channels = hidden_size * 2, kernel_size = kernel_size, stride = 1, padding = calculate_padding(input_size / 2))\n",
    "    self.linear = nn.Linear(in_features = int(((input_size/4)**2) * (hidden_size*2)), out_features = output_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.pool2d = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool2d(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool2d(x)\n",
    "    x = x.view(-1, self.linear.in_features)\n",
    "    x = self.linear(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "bs = 128\n",
    "criterion = nn.CrossEntropyLoss().to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "A = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label = np.arange(1, len(A[1][0]) + 1)\n",
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "ax.plot(x_label, A[1][0], label = 'SimpleCNN')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.show()\n",
    "fig.savefig('SimpleCNN.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "bs = 128\n",
    "criterion = nn.CrossEntropyLoss().to(dev)\n",
    "\n",
    "lr = 0.01\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "A = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "lr = 0.1\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "B = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "lr = 1.0\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "C = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "lr = 10\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "D = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label = np.arange(1, len(A[1][0]) + 1)\n",
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "ax.plot(x_label, A[1][0], label = 'LR = 0.01')\n",
    "ax.plot(x_label, B[1][0], label = 'LR = 0.1')\n",
    "ax.plot(x_label, C[1][0], label = 'LR = 1.0')\n",
    "ax.plot(x_label, D[1][0], label = 'LR = 10')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('Learning Rate.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 0.1\n",
    "criterion = nn.CrossEntropyLoss().to(dev)\n",
    "\n",
    "bs = 128\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "A = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "bs = 256\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "B = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "bs = 512\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "C = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "bs = 2048\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "D = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "ax.plot(np.arange(1, len(A[1][0]) + 1), A[1][0], label = 'BS = 32')\n",
    "ax.plot(np.arange(1, len(B[1][0]) + 1), B[1][0], label = 'BS = 64')\n",
    "ax.plot(np.arange(1, len(C[1][0]) + 1), C[1][0], label = 'BS = 128')\n",
    "ax.plot(np.arange(1, len(D[1][0]) + 1), D[1][0], label = 'BS = 2048')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "fig.savefig('Batch Size.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted CrossEntropyLoss vs Unbalanced CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.Tensor([0.506500084,\n",
    "                       0.444971818,\n",
    "                       0.503524673,\n",
    "                       0.489316588,\n",
    "                       0.513522766,\n",
    "                       0.553403431,\n",
    "                       0.506928016,\n",
    "                       0.478850758,\n",
    "                       0.512732866,\n",
    "                       0.504286435])\n",
    "\n",
    "weight = torch.Tensor([1.013000169,\n",
    "                       0.889943637,\n",
    "                       1.007049345,\n",
    "                       0.978633176,\n",
    "                       1.027045532,\n",
    "                       1.106806862,\n",
    "                       1.013856032,\n",
    "                       0.957701516,\n",
    "                       1.025465732,\n",
    "                       1.008572869])\n",
    "\n",
    "epochs = 1\n",
    "lr = 0.1\n",
    "bs = 128\n",
    "\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "criterion = nn.CrossEntropyLoss().to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "A = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "criterion = nn.CrossEntropyLoss(weight = weight).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "B = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "ax.plot(np.arange(1, len(A[1][0]) + 1), A[1][0], label = 'Unbalanced CrossEntropyLoss')\n",
    "ax.plot(np.arange(1, len(B[1][0]) + 1), B[1][0], label = 'Weighted CrossEntropyLoss')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "fig.savefig('Loss Functions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 0.1\n",
    "bs = 128\n",
    "criterion = nn.CrossEntropyLoss().to(dev)\n",
    "\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr, momentum = 0.0)\n",
    "A = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr, momentum = 0.1)\n",
    "B = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr, momentum = 0.9)\n",
    "C = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr, momentum = 5.0)\n",
    "D = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "ax.plot(np.arange(1, len(A[1][0]) + 1), A[1][0], label = 'Momentum = 0.0')\n",
    "ax.plot(np.arange(1, len(B[1][0]) + 1), B[1][0], label = 'Momentum = 0.1')\n",
    "ax.plot(np.arange(1, len(C[1][0]) + 1), C[1][0], label = 'Momentum = 0.9')\n",
    "ax.plot(np.arange(1, len(D[1][0]) + 1), D[1][0], label = 'Momentum = 5.0')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "fig.savefig('Momentum.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 0.1\n",
    "bs = 128\n",
    "criterion = nn.CrossEntropyLoss().to(dev)\n",
    "\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr, weight_decay = 0.0)\n",
    "A = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr, weight_decay = 0.01)\n",
    "B = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr, weight_decay = 0.1)\n",
    "C = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr, weight_decay = 1.0)\n",
    "D = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "ax.plot(np.arange(1, len(A[1][0]) + 1), A[1][0], label = 'Weight Decay = 0.0')\n",
    "ax.plot(np.arange(1, len(B[1][0]) + 1), B[1][0], label = 'Weight Decay = 0.01')\n",
    "ax.plot(np.arange(1, len(C[1][0]) + 1), C[1][0], label = 'Weight Decay = 0.1')\n",
    "ax.plot(np.arange(1, len(D[1][0]) + 1), D[1][0], label = 'Weight Decay = 1.0')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "fig.savefig('L2 Regularization.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "bs = 128\n",
    "criterion = nn.CrossEntropyLoss().to(dev)\n",
    "\n",
    "lr = 0.1\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr, momentum = 0.9)\n",
    "A = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "lr = 0.01\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.Adagrad(net.parameters(), lr)\n",
    "B = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "lr = 0.001\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr)\n",
    "C = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "ax.plot(np.arange(1, len(A[1][0]) + 1), A[1][0], label = 'SGD + Momentum + Decay')\n",
    "ax.plot(np.arange(1, len(B[1][0]) + 1), B[1][0], label = 'Adagrad + Weight Decay')\n",
    "ax.plot(np.arange(1, len(C[1][0]) + 1), C[1][0], label = 'Adam + Weight Decay')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "fig.savefig('Optimizer.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 0.1\n",
    "bs = 128\n",
    "criterion = nn.CrossEntropyLoss().to(dev)\n",
    "\n",
    "net = SimpleCNN(1, 28, 5, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "A = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net = SimpleCNN(1, 28, 10, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "B = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "C = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net = SimpleCNN(1, 28, 100, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "D = train_epochs(net, bs, criterion, optimizer, epochs, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "ax.plot(np.arange(1, len(A[1][0]) + 1), A[1][0], label = 'Conv1 Channels = 5')\n",
    "ax.plot(np.arange(1, len(B[1][0]) + 1), B[1][0], label = 'Conv1 Channels = 10')\n",
    "ax.plot(np.arange(1, len(C[1][0]) + 1), C[1][0], label = 'Conv1 Channels = 50')\n",
    "ax.plot(np.arange(1, len(D[1][0]) + 1), D[1][0], label = 'Conv1 Channels = 100')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "fig.savefig('Network Width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Depth1(nn.Module):\n",
    "\n",
    "  def __init__(self, in_channels, input_size, hidden_size, output_size, kernel_size = 3, stride = 1):\n",
    "    super(Depth1, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = hidden_size, kernel_size = kernel_size, stride = 1, padding = calculate_padding(input_size))\n",
    "    self.linear = nn.Linear(in_features = int(((input_size/2)**2) * hidden_size), out_features = output_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.pool2d = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool2d(x)\n",
    "    x = x.view(-1, self.linear.in_features)\n",
    "    x = self.linear(x)\n",
    "    return x\n",
    "\n",
    "class Depth3(nn.Module):\n",
    "\n",
    "  def __init__(self, in_channels, input_size, hidden_size, output_size, kernel_size = 3, stride = 1):\n",
    "    super(Depth3, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = hidden_size, kernel_size = kernel_size, stride = 1, padding = calculate_padding(input_size))\n",
    "    self.conv2 = nn.Conv2d(in_channels = hidden_size, out_channels = hidden_size * 2, kernel_size = kernel_size, stride = 1, padding = calculate_padding(input_size / 2))\n",
    "    self.conv3 = nn.Conv2d(in_channels = hidden_size * 2, out_channels = hidden_size * 4, kernel_size = kernel_size, stride = 1, padding = calculate_padding(input_size / 4))\n",
    "    self.linear = nn.Linear(in_features = int((np.floor(input_size/8)**2) * (hidden_size*4)), out_features = output_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.pool2d = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool2d(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool2d(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool2d(x)\n",
    "    x = x.view(-1, self.linear.in_features)\n",
    "    x = self.linear(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 0.1\n",
    "bs = 128\n",
    "criterion = nn.CrossEntropyLoss().to(dev)\n",
    "\n",
    "net1 = Depth1(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net1.parameters(), lr)\n",
    "A = train_epochs(net1, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net2 = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net2.parameters(), lr)\n",
    "B = train_epochs(net2, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net3 = Depth3(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net3.parameters(), lr)\n",
    "C = train_epochs(net3, bs, criterion, optimizer, epochs, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "ax.plot(np.arange(1, len(A[1][0]) + 1), A[1][0], label = 'Conv Layers = 1')\n",
    "ax.plot(np.arange(1, len(B[1][0]) + 1), B[1][0], label = 'Conv Layers = 2')\n",
    "ax.plot(np.arange(1, len(C[1][0]) + 1), C[1][0], label = 'Conv Layers = 3')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "fig.savefig('Network Depth by Convolutional Layers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Depth by Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Depth2(nn.Module):\n",
    "\n",
    "  def __init__(self, in_channels, input_size, hidden_size, output_size, kernel_size = 3, stride = 1):\n",
    "    super(Depth2, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = hidden_size, kernel_size = kernel_size, stride = 1, padding = calculate_padding(input_size))\n",
    "    self.conv2 = nn.Conv2d(in_channels = hidden_size, out_channels = hidden_size * 2, kernel_size = kernel_size, stride = 1, padding = calculate_padding(input_size / 2))\n",
    "    self.linear1 = nn.Linear(in_features = int(((input_size/4)**2) * (hidden_size*2)), out_features = int(((input_size/4)**2) * hidden_size))\n",
    "    self.linear2 = nn.Linear(in_features = self.linear1.out_features, out_features = output_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.pool2d = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool2d(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool2d(x)\n",
    "    x = x.view(-1, self.linear1.in_features)\n",
    "    x = self.linear1(x)\n",
    "    x = self.linear2(x)\n",
    "    return x\n",
    "\n",
    "class Depth3(nn.Module):\n",
    "\n",
    "  def __init__(self, in_channels, input_size, hidden_size, output_size, kernel_size = 3, stride = 1):\n",
    "    super(Depth3, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = hidden_size, kernel_size = kernel_size, stride = 1, padding = calculate_padding(input_size))\n",
    "    self.conv2 = nn.Conv2d(in_channels = hidden_size, out_channels = hidden_size * 2, kernel_size = kernel_size, stride = 1, padding = calculate_padding(input_size / 2))\n",
    "    self.linear1 = nn.Linear(in_features = int(((input_size/4)**2) * (hidden_size*2)), out_features = int(((input_size/4)**2) * hidden_size))\n",
    "    self.linear2 = nn.Linear(in_features = self.linear1.out_features, out_features = int(self.linear1.out_features/2))\n",
    "    self.linear3 = nn.Linear(in_features = self.linear2.out_features, out_features = output_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.pool2d = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool2d(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool2d(x)\n",
    "    x = x.view(-1, self.linear1.in_features)\n",
    "    x = self.linear1(x)\n",
    "    x = self.linear2(x)\n",
    "    x = self.linear3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 0.1\n",
    "bs = 128\n",
    "criterion = nn.CrossEntropyLoss().to(dev)\n",
    "\n",
    "net1 = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net1.parameters(), lr)\n",
    "A = train_epochs(net1, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net2 = Depth2(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net2.parameters(), lr)\n",
    "B = train_epochs(net2, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net3 = Depth3(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net3.parameters(), lr)\n",
    "C = train_epochs(net3, bs, criterion, optimizer, epochs, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "ax.plot(np.arange(1, len(A[1][0]) + 1), A[1][0], label = 'FC Layers = 1')\n",
    "ax.plot(np.arange(1, len(B[1][0]) + 1), B[1][0], label = 'FC Layers = 2')\n",
    "ax.plot(np.arange(1, len(C[1][0]) + 1), C[1][0], label = 'FC Layers = 3')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "fig.savefig('Network Depth by Fully Connected Layers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 0.1\n",
    "bs = 128\n",
    "criterion = nn.CrossEntropyLoss().to(dev)\n",
    "\n",
    "resnet18 = torchvision.models.resnet18(pretrained = True)\n",
    "resnet18.conv1 = nn.Conv2d(1, 64, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "resnet18.to(dev)\n",
    "optimizer = torch.optim.SGD(resnet18.parameters(), lr)\n",
    "A = train_epochs(resnet18, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "resnet34 = torchvision.models.resnet18(pretrained = True)\n",
    "resnet34.conv1 = nn.Conv2d(1, 64, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "resnet34.to(dev)\n",
    "optimizer = torch.optim.SGD(resnet34.parameters(), lr)\n",
    "B = train_epochs(resnet34, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "resnet50 = torchvision.models.resnet18(pretrained = True)\n",
    "resnet50.conv1 = nn.Conv2d(1, 64, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "resnet50.to(dev)\n",
    "optimizer = torch.optim.SGD(resnet50.parameters(), lr)\n",
    "C = train_epochs(resnet50, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "resnet101 = torchvision.models.resnet18(pretrained = True)\n",
    "resnet101.conv1 = nn.Conv2d(1, 64, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "resnet101.to(dev)\n",
    "optimizer = torch.optim.SGD(resnet101.parameters(), lr)\n",
    "D = train_epochs(resnet101, bs, criterion, optimizer, epochs, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "ax.plot(np.arange(1, len(A[1][0]) + 1), A[1][0], label = 'ResNet18')\n",
    "ax.plot(np.arange(1, len(B[1][0]) + 1), B[1][0], label = 'ResNet34')\n",
    "ax.plot(np.arange(1, len(C[1][0]) + 1), C[1][0], label = 'ResNet50')\n",
    "ax.plot(np.arange(1, len(D[1][0]) + 1), D[1][0], label = 'ResNet101')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "fig.savefig('ResNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Improvements: DropOut Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropOut(nn.Module):\n",
    "\n",
    "  def __init__(self, in_channels, input_size, hidden_size, output_size, kernel_size = 3, stride = 1):\n",
    "    super(DropOut, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = hidden_size, kernel_size = kernel_size, stride = 1, padding = calculate_padding(input_size))\n",
    "    self.conv2 = nn.Conv2d(in_channels = hidden_size, out_channels = hidden_size * 2, kernel_size = kernel_size, stride = 1, padding = calculate_padding(input_size / 2))\n",
    "    self.linear1 = nn.Linear(in_features = int(((input_size/4)**2) * (hidden_size*2)), out_features = int(((input_size/4)**2) * hidden_size))\n",
    "    self.linear2 = nn.Linear(in_features = self.linear1.out_features, out_features = output_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.pool2d = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "    self.dropout = nn.Dropout()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool2d(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool2d(x)\n",
    "    x = x.view(-1, self.linear1.in_features)\n",
    "    x = self.dropout(x)\n",
    "    x = self.linear1(x)\n",
    "    x = self.dropout(x)\n",
    "    x = self.linear2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 0.1\n",
    "bs = 128\n",
    "criterion = nn.CrossEntropyLoss().to(dev)\n",
    "\n",
    "net1 = SimpleCNN(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net1.parameters(), lr)\n",
    "A = train_epochs(net1, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net2 = DropOut(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net2.parameters(), lr)\n",
    "B = train_epochs(net2, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "net3 = DropOut(1, 28, 50, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net3.parameters(), lr, momentum = 0.9, weight_decay = 0.01)\n",
    "C = train_epochs(net3, bs, criterion, optimizer, epochs, show_progress = False)\n",
    "\n",
    "epochs = 10\n",
    "net4 = DropOut(1, 28, 100, 10).to(dev)\n",
    "optimizer = torch.optim.SGD(net4.parameters(), lr, momentum = 0.9)\n",
    "D = train_epochs(net4, bs, criterion, optimizer, epochs, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "ax.plot(np.arange(1, len(A[1][0]) + 1), A[1][0], label = 'Vanilla')\n",
    "ax.plot(np.arange(1, len(B[1][0]) + 1), B[1][0], label = 'Dropout')\n",
    "ax.plot(np.arange(1, len(C[1][0]) + 1), C[1][0], label = 'Dropout + Momentum + Weight Decay')\n",
    "ax.plot(np.arange(1, len(D[1][9]) + 1), D[1][9], label = '100 Channels + Momentum + 10 Epochs')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "fig.savefig('Improvements')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
